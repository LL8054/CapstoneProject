foundWordsShort <- foundWords[1:3]
print(foundWordsShort)
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor3.R')
input <- "Hey sunshine, can you follow me and make me the"
NextWordPredictor3("Hey sunshine, can you follow me and make me the")
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor3.R')
NextWordPredictor3("Hey sunshine, can you follow me and make me the")
NextWordPredictor3("Very early observations on the Bills game: Offense still struggling but the")
NextWordPredictor3("When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd")
NextWordPredictor3("Guy at my table's wife got up to go to the bathroom and I asked about dessert and he started telling me about his")
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor3.R')
NextWordPredictor3("Guy at my table's wife got up to go to the bathroom and I asked about dessert and he started telling me about his")
input <- "Guy at my table's wife got up to go to the bathroom and I asked about dessert and he started telling me about his"
input <- tolower(input)
input <- strsplit(input, " ")[[1]]
input <- gsub("[,.:;?!']\\s*", "", input)
inputTail <- tail(input, 3)
n <- as.numeric(length(inputTail))
if (n == 3) {
grams <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/quadgramsDT25.rds")
gramsFreq <- grams[order(count, decreasing=TRUE)]
}
foundGrams <- gramsFreq[grepl(paste(c("^",paste(inputTail, collapse=" ")), collapse=""), gramsFreq$token)]
identical(as.numeric(nrow(foundGrams)), 0)
input2 <- paste(input, collapse=" ")
inputCorpus <- Corpus(VectorSource(input2))
inputClean <- tm_map(inputCorpus, removeNumbers)
inputClean <- tm_map(inputClean, removeWords, stopwords("english"))
inputClean <- tm_map(inputClean, removePunctuation)
inputClean <- tm_map(inputClean, content_transformer(tolower))
swearWords <- readLines("~/datasciencecoursera/Courses/Capstone/CapstoneProject/swearWords.csv") # as downloaded from http://www.bannedwordlist.com/
swearWords <- paste(swearWords[1:length(swearWords)])
inputClean <- tm_map(inputClean, removeWords, swearWords)
inputClean <- tm_map(inputClean, stripWhitespace)
df <- data.frame(text=unlist(sapply(inputClean, `[`, "content")), stringsAsFactors=F)
lastWords <- strsplit(df[nrow(df), ncol(df)], " ")[[1]]
foundFailTail <- tail(lastWords, 3)
trigramsDTprune25 <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/trigramsDTprune25.rds")
trigramsDTprune25 <- trigramsDTprune25[order(count, decreasing=TRUE)]
foundFailGrams <- trigramsDTprune25[grepl(paste(c("^",paste(foundFailTail, collapse=" ")), collapse=""),
trigramsDTprune25$token)]
identical(as.numeric(nrow(foundFailGrams)),0)
inputTail2 <- inputTail[-1]
foundGrams2 <- gramsFreq[grepl(paste(c("^",paste(inputTail2, collapse=" ")), collapse=""), gramsFreq$token)]
identical(as.numeric(nrow(foundGrams2)), 0)
inputTail3 <- inputTail2[length(inputTail2)]
foundGrams3 <- gramsFreq[grepl(inputTail3, gramsFreq$token)]
identical(as.numeric(nrow(foundGrams2)), 0)
foundGrams3
identical(as.numeric(nrow(foundGrams3)), 0)
3 <- length(inputTail3)
foundNames <- names(foundGrams3)
foundWords <- as.character()
foundWords <- foundGrams3[[n3+1]]
n3 <- length(inputTail3)
foundNames <- names(foundGrams3)
foundWords <- as.character()
foundWords <- foundGrams3[[n3+1]]
as.numeric(length(foundWords)) < 4
foundWordsShort <- foundWords[1:3]
print(foundWordsShort)
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor3.R')
NextWordPredictor3("Guy at my table's wife got up to go to the bathroom and I asked about dessert and he started telling me about his")
NextWordPredictor3("I'd give anything to see arctic monkeys this")
system.time(NextWordPredictor3("Talking to your mom has the same effect as a hug and helps reduce your"))
system.time(NextWordPredictor3("When you were in Holland you were like 1 inch away from me but you hadn't time to take a"))
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor3.R')
system.time(NextWordPredictor3("When you were in Holland you were like 1 inch away from me but you hadn't time to take a"))
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor3.R')
system.time(NextWordPredictor3("When you were in Holland you were like 1 inch away from me but you hadn't time to take a"))
system.time(NextWordPredictor3("I'd just like all of these questions answered, a presentation of evidence, and a jury to settle the"))
system.time(NextWordPredictor3("I can't deal with unsymetrical things. I can't even hold an uneven number of bags of groceries in"))
system.time(NextWordPredictor3("Every inch of you is perfect from the bottom to the"))
system.time(NextWordPredictor3("I'm thankful my childhood was filled with imagination and bruises from playing"))
system.time(NextWordPredictor3("I like how the same people are in almost all of Adam Sandler's"))
system.time(NextWordPredictor3("The guy in front of me just bought a pound of bacon, a bouquet, and a case of"))
system.time(NextWordPredictor3("You're the reason why I smile everyday. Can you follow me please? It would mean the"))
system.time(NextWordPredictor3("Go on a romantic date at the"))
system.time(NextWordPredictor3("Well I'm pretty sure my granny has some old bagpipes in her garage I'll dust them off and be
on my"))
system.time(NextWordPredictor3("Ohhhhh #PointBreak is on tomorrow. Love that film and haven't seen it in quite some"))
system.time(NextWordPredictor3("After the ice bucket challenge Louis will push his long wet hair out of his eyes with his little"))
system.time(NextWordPredictor3("Be grateful for the good times and keep the faith during the"))
system.time(NextWordPredictor3("If this isn't the cutest thing you've ever seen, then you must be"))
?textInput
library(shiny)
install.packages("shiny")
library(shiny)
?textInput
library(shiny)
p("more info",
)
)
value=1700, min=1500, max=2500, step=25),
textInput('Input', value='Enter text...',),
textInput('Input', value='Enter text...'),
submitButton("Submit")
verbatimTextOutput('result')
)
textInput('Input', value='Enter text...',),
)
verbatimTextOutput("result")
p("Type in a word or phrase, hit submit, and the app predicts the next word.",
mainPanel(
devtools::install_github("rstudio/shinyapps")
library(shinyapps)
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
?textInput
?sliderInput
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
install.packages("UsingR")
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
?is.data.frame
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
?renderText
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
t?htr
?httr
install.packages("httr")
library(httr)
?httr
GET("http://google.com")
GET("http://google.com/", path = "search", query = list(q = "ham"))
a <- "texas"
aa <- GET("http://google.com/", path="search", query=list(q=a))
aa
HEAD("http://google.com")
aa <- HEAD("http://google.com/", path="search", query=list(q=a))
aa
aa <- GET("http://google.com/", path="search", query=list(q=a))
?httr
content(aa)
install.packages("XML")
library(XML)
content(aa)
head(content(aa))
class(content(aa))
aa <- POST("http://google.com/", path="search", query=list(q=a))
aa
cat(content(aa))
r <- POST("http://httpbin.org/post", body = list(a = 1, b = 2))
content(r)
r
cat(content(r, "text"), "\n")
r <- POST("http://google.com", path = "search", query = list(q = "ham"), body = list(a = 1, b = 2))
r
r <- POST("http://google.com", path = "search", query = list(q = "ham"))
r
tail(4)
tail(r)
names$r
r$names
names(r)
r$content
r <- POST("http://google.com", path = "search", query = list(q = "ham"), as=text)
r
class(r)
?httr
content(r, as=text)
content(r, as="text")
GET("http://google.com/", query = list(q = "ham"))
GET("http://google.com/", path = "search", query = list(q = "ham"))
a <- GET("http://google.com/", path = "search", query = list(q = "ham"))
names(a)
a$content
a
names(a)
names[1]
names[[1]]
names$url
a$url
a[1]
a[2]
a[3]
a[4]
a[5]
a[6]
a[7]
a[8]
a[9]
a
head(a)
tail(a)
library(RCurl)
library(XML)
site <- getForm("http://www.google.com/search", hl="en",
lr="", q="r-project", btnG="Search")
site
htmlParseTree(site)
htmlTreeParse(site)
a
htmlTreeParse(a)
searchResult <- GET("http://google.com/", path = "search", query = list(q = "texas"))
searchResult
typeof(searchResult)
gregexpr('<span.>.</span.>', searchResult)
gregexpr('<span[.]>[.]</span[.]>', searchResult)
gregexpr("<span[.]>[.]</span[.]>", searchResult)
gregexpr("<span.>.</span.>", searchResult)
extract <- gregexpr("<span.>.</span.>", searchResult, fixed=TRUE)[[1]]
extract
extract <- gregexpr("<span.>.</span.>", searchResult)
extract[[1]][1]
searchResult
?first
?substring
searchResult <- GET("http://google.com/", path = "search", query = list(q = "texas"))
htmlTreeParse(searchResult)
gregexpr("<span>.</span>", searchResult)
stringExtract <- substring(searchResult, first=1, last = 30)
posResults <- gregexpr("<span>.</span>", stringExtract)
posFirst <- posResults[[1]][1]
posFirst
posResults
posExtractStart <- gregexpr("<span.>", searchResult, fixed = TRUE)[[1]]
stringExtract <- substring(searchResult, first=posExtractStart, last = posExtractStart + 30)
posResults <- gregexpr("<span>.</span>", stringExtract)
posFirst <- posResults[[1]][1]
posFirst
library(XML)
library(RCurl)
library(httr)
searchResult <- GET("http://google.com/", path = "search", query = list(q = "texas"))
searchResult <- htmlTreeParse(searchResult)
class(searchResult)
posExtractStart <- gregexpr("<span.>", searchResult, fixed = TRUE)[[1]]
stringExtract <- substring(searchResult, first=posExtractStart, last = posExtractStart + 30)
posResults <- gregexpr("<span>.</span>", stringExtract)
posFirst <- posResults[[1]][1]
posFirst
typeof(searchResult)
searchResult
a <- paste(searchResult)
a
class(a)
posExtractStart <- gregexpr("value = \", searchResult, fixed = TRUE)[[1]]
stringExtract <- substring(searchResult, first=posExtractStart, last = posExtractStart + 30)
posResults <- gregexpr("value.\\".\\"\", stringExtract)
posExtractStart <- gregexpr("value", searchResult, fixed = TRUE)[[1]]
stringExtract <- substring(searchResult, first=posExtractStart, last = posExtractStart + 30)
posResults <- gregexpr("value", stringExtract)
posFirst <- posResults[[1]][1]
posFirts
posFirst
searchResult <- GET("http://google.com/", path = "search", query = list(q = "texas"))
searchResult
grep("Geograph", searchResult)
?grep
grep("Geograph", searchResult, value=TRUE)
grepl("Geograph", searchResult)
a <- as.character(searchResult <- GET("http://google.com/", path = "search", query = list(q = "texas")))
a
grepl("Geograph", a)
grep("Geograph", a, value=TRUE)
grep("geograph", a)
searchResult <- htmlTreeParse(searchResult)
searchResult
getURL(http://www.google.com)
getURL("http://www.google.com")
htmlTreeParse(getURL("http://www.google.com"))
site <- getForm("http://www.google.com/search", hl="en",
lr="", q="Texas", btnG="Search")
site
posExtractStart <- gregexpr("value", searchResult, fixed = TRUE)[[1]]
stringExtract <- substring(searchResult, first=posExtractStart, last = posExtractStart + 30)
posResults <- gregexpr("value", stringExtract)
posFirst <- posResults[[1]][1]
textLength  <- attributes(posResults[[1]])$match.length
stringExtract <- substring(stringExtract, first=posFirst, last = posFirst + textLength)
stringExtract <- gsub("[^0-9]", "", stringExtract)
posResults
htmlTreeParse(searchResults)
searchResult <- getForm("http://www.google.com/search", hl="en", lr="", q="Texas", btnG="Search")
searchResult <- htmlTreeParse(searchResult)
searchResult
typeof(searchResult)
searchResult <- getForm("http://www.google.com/search", hl="en", lr="", q="Texas", btnG="Search")
searchResult <- htmlTreeParse(searchResult)
indicator <- "<span>"
posExtractStart <- gregexpr(indicator, searchResult, fixed = TRUE)[[1]]
stringExtract <- substring(searchResult, first=posExtractStart, last = posExtractStart + 30)
#posResults <- gregexpr("value", stringExtract)
posFirst <- stringExtract[[1]][1]
posFirst
searchResult
searchResult <- getForm("http://www.google.com/search", hl="en", lr="", q="Texas", btnG="Search")
searchResult <- htmlTreeParse(searchResult)
indicator <- "<span class="st">"
posExtractStart <- gregexpr(indicator, searchResult, fixed = TRUE)[[1]]
stringExtract <- substring(searchResult, first=posExtractStart, last = posExtractStart + 30)
#posResults <- gregexpr("value", stringExtract)
posFirst <- stringExtract[[1]][1]
indicator <- "<span class=\\"st\\">"
indicator <- "<span class=\\s"st\\s">"
indicator <- "<span class=">"
indicator <- "<span class=>"
searchResult <- getForm("http://www.google.com/search", hl="en", lr="", q="Texas", btnG="Search")
searchResult <- htmlTreeParse(searchResult)
indicator <- "<span class=>"
posExtractStart <- gregexpr(indicator, searchResult, fixed = TRUE)[[1]]
stringExtract <- substring(searchResult, first=posExtractStart, last = posExtractStart + 30)
#posResults <- gregexpr("value", stringExtract)
posFirst <- stringExtract[[1]][1]
posFirst
?getForm
searchResult
posFirst
stringExtract
posExtractStart
site <- getForm("http://www.google.com/search", hl="en",
lr="", q="r-project", btnG="Search")
htmlTreeParse(site)
indicatorWord <- "of about"
siteHTML <- htmlTreeParse(site)
posExtractStart <- gregexpr(indicatorWord, siteHTML,
fixed = TRUE)[[1]]
stringExtract <- substring(siteHTML, first=posExtractStart,
last = posExtractStart + 30)
posResults <- gregexpr('<b>[0-9.,]{1,20}</b>', stringExtract)
posFirst <- posResults[[1]][1]
textLength  <- attributes(posResults[[1]])$match.length
stringExtract <- substring(stringExtract, first=posFirst,
last = posFirst + textLength)
stringExtract <- gsub("[^0-9]", "", stringExtract)
print(stringExtract)
posFirst
posResults
gregexpr(indicatorWord, siteHTML,
+                             fixed = TRUE)[[1]]
gregexpr(indicatorWord, siteHTML,fixed = TRUE)[[1]]
?Htr
?httr
searchResult <- GET("http://google.com/", path = "search", query = list(q = "ham"))
searchResult
searchResult <- GET("http://google.com/", path = "search", query = list(q = "texas"))
searchResult
names(searchResult)
names(htmlTreeParse(searchResult))
searchResult$url
searchResultA$status_code
searchResult$statusCode
searchResult$status_code
searchResult$headers
searchResults$all_headers
searchResult$all_headers
names(searchResult)
searchResult$cookies
searchResult$content
searchResult$content[1]
names(searchResult)
searchResult$date
searchResult[1]
searchResult$times
searchResult$request
searchResult$handle
?setkey
DT = data.table(A=5:1,B=letters[5:1])
library(data.table)
DT = data.table(A=5:1,B=letters[5:1])
DT
setkey(DT,B)
DT
tables()
key(DT)
input <- "hello my name is"
library(shiny)
options(warn=-1)
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder.R')
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder1.R')
library(stringi)
library(tm)
library(quanteda)
library(RWeka)
library(tm)
library(tau)
i <- input
inp <- tolower(i)
inp <- strsplit(inp, " ")[[1]]
inp <- gsub("[,.:;?!']\\s*", "", inp)
inputTail <- tail(inp, 3)
n <- as.numeric(length(inputTail))
n
if (n == 3) {
grams <- readRDS("data/quadgramsDT25.rds")
gramsFreq <- grams[order(count, decreasing=TRUE)]
}
if (n == 3) {
grams <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/quadgramsDT25.rds")
gramsFreq <- grams[order(count, decreasing=TRUE)]
}
system.time(gramsFreq <- grams[order(count, decreasing=TRUE)])
system.time(grams <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/quadgramsDT25.rds"))
system.time(grams <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/quadgramsDTprune25.rds"))
system.time(grams <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/trigramsDTprune25.rds"))
system.time(grams <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/bigramsDTprune25.rds"))
system.time(grams <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/bigramsDTprune25.rds"))
subset25 <- readRDS(("~/datasciencecoursera/Courses/Capstone/Subsets/Subset25.rds"))
s1 <- subset25
system.time(b1 <- dfm(s1, ngrams = 2))
library(stringi)
library(tm)
library(quanteda)
library(RWeka)
library(tm)
library(tau)
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt") #user 3.437, system .496, elapsed 3.982
set.seed(100)
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.1, replace=FALSE)
enTwitter <- readLines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.twitter.txt")
set.seed(100)
enTwitterSubset <- sample(enTwitter, size=length(enTwitter)*.1, replace=FALSE)
enNews <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.news.txt")
set.seed(100)
enNewsSubset <- sample(enNews, size=length(enNews)*.1, replace=FALSE)
subset <- c(enBlogsSubset, enTwitterSubset, enNewsSubset)
b1 <- subset
system.time(b1 <- dfm(s1, ngrams = 2))
library(quanteda)
system.time(b1 <- dfm(s1, ngrams = 2))
class(b1)
class(s1)
s1 <- subset
system.time(b1 <- dfm(s1, ngrams = 2))
saveRDS(b1, file = "~/datasciencecoursera/Courses/Capstone/Subsets/bigrams10.rds")
rm(b1)
system.time(b1 <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/bigrams10.rds"))
system.time(grams <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/quadgramsDTprune25.rds"))
system.time(t1 <- dfm(s1, ngrams = 3))
saveRDS(t1, file = "~/datasciencecoursera/Courses/Capstone/Subsets/trigrams10.rds")
system.time(t1 <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/trigrams10.rds"))
system.time(q1 <- dfm(s1, ngrams = 4))
saveRDS(q1, file = "~/datasciencecoursera/Courses/Capstone/Subsets/quadgrams10.rds")
system.time(q <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/quadgrams10.rds"))
library(tm)
library(stringi)
library(RWeka)
library(SnowballC)
library(slam)
library(data.table)
library(tidyr)
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt",
encoding="UTF-8")
set.seed(100)
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.01, replace=FALSE)
enTwitter <- readLines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.twitter.txt",
encoding="UTF-8")
set.seed(100)
enTwitterSubset <- sample(enTwitter, size=length(enTwitter)*.01, replace=FALSE)
enNews <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.news.txt",
encoding="UTF-8")
set.seed(100)
enNewsSubset <- sample(enNews, size=length(enNews)*.01, replace=FALSE)
subset <- c(enBlogsSubset, enTwitterSubset, enNewsSubset)
s1 <- subset
b1 <- dfm(s1, ngrams=2)
library(quanteda)
b1 <- dfm(s1, ngrams=2)
saveRDS(b1, file = "~/datasciencecoursera/Courses/Capstone/Subsets/bigrams01.rds")
t1 <- dfm(s1, ngrams=3)
saveRDS(t1, file = "~/datasciencecoursera/Courses/Capstone/Subsets/trigrams01.rds")
q1 <- dfm(s1, ngrams=4)
saveRDS(q1, file = "~/datasciencecoursera/Courses/Capstone/Subsets/quadgrams01.rds")
system.time(b1 <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/quadgrams01.rds"))
system.time(t1 <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/trigrams01.rds"))
system.time(q1 <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/qudgrams01.rds"))
system.time(q1 <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/quadgrams01.rds"))
system.time(b1 <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/bigrams01.rds"))
u1 <- dfm(s1)
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
a <- readRDS("data/bigramsDT25.rds")
a <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/Unigrams.rds")
class(a)
b <- readRDS"(~/datasciencecoursera/Courses/Capstone/Subsets/bigrams10.rds")
b <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/bigrams10.rds")
class(b)
b <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/bigrams01.rds")
class(b)
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
a <- readRDS("~/datasciencecoursera/Courses/Capstone/Subsets/trigrams01.rds")
class(a)
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
update.packages()
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor3.R')
NextWordPredictor3("hello my name is")
exit
shiny::runApp('datasciencecoursera/Courses/Capstone/capstoneproject/App')
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor3.R')
NextWordPredictor3("hello my name is")
setwd("~/datasciencecoursera/Courses/Capstone/capstoneproject")
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor3.R')
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor3.R')
NextWordPredictor3("hello my name is")
showConnections(all=T)
closeAllConnections()
showConnections(all=T)
