head(ElemStatLearn)
ElemStatLearn
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train
class(vowel.train)
colnames(vowel.train)
class(vowel.train$y)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
class(vowel.test$y)
set.seed(33833)
modelFit <- train(y~., vowel.train, method="rf")
order(varImp(modelFit))
set.seed(33833)
modelFit <- train(y~., vowel.train, method="rf", prox=TRUE)
order(varImp(modelFit))
modelFit
varImp(modelFit)
order(varImp(modelFit))
class(modelFit)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
varImp(a)
order(varImp(a))
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelFit <- train(y~., vowel.train, method="rf", prox=TRUE)
varImp(modelFit)
prediction <- predict(vowel.test, modelFit)
prediction <- predict(modelFit, vowel.test)
varImp(prediction)
prediction
modelFit
prediction
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(3833)
modelFit <- train(y~., vowel.train, method="rf", prox=TRUE)
varImp(modelFit)
library(ISLR)
install.packages("ISLR")
library(ISLR)
data(Wage)
library(ggplot2)
library(caret)
inBuild <- createDataPartition(y=Wage$wage, p=.7, list=FALSE)
validation <- Wage[-inBuild,]
buildData <- Wage[inBuild]
inTrain <- createDataPartition(y=buildData$wage, p=.7, list=FALSE)
buildData <- Wage[inBuild,]
inTrain <- createDataPartition(y=buildData$wage, p=.7, list=FALSE)
training <- buildData[inTrain,]
testing <- buildData[-inTrain,]
dim(training)
dim(testing)
dim(validatin)
dim(validation)
mod1 <- train(wage ~ ., method="glm", data=training)
mod2 <- train(wage ~., method="rf", data=training, trControl=trainControl(method="cv"), number=3)
pred1 <- predict(mod1, testing)
pred1
pred2 <- predict(mod2, testing)
qplot(pred1, pred2, color=wage, data=testing)
testing$wage
training$wage
preDF <- data.frame(pred1, pred2, wage=testing$wage)
preDF
head(preDF)
exit
a <- c(4, 0, 4, 0, 3, 0, 10, 1, 6, 4, 3, 8, 2, 3, 1, 10, 7, 5, 2, 1, 5, 1, 1, 2)
plot(a)
hist(a)
hist(a, breaks=10)
hist(a, breaks=12)
hist(a, breaks=c(0:10))
hist(a, breaks=c(0:11))
hist(a, breaks=c(0:10))
mean(a)
abline(v = mean(a), col = "blue", lwd = 2)
hist(a, breaks=10, main="Rangers Runs Per Game in April"
)
hist(a, breaks=10, main="Rangers Runs Per Game in April", x.lab="Runs Per Game")
hist(a, breaks=10, main="Rangers Runs Per Game in April", xlab="Runs Per Game")
abline(v = mean(a), col = "blue", lwd = 2)
library(stringi)
library(tm)
library(quanteda)
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder.R')
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt") #user 3.437, system .496, elapsed 3.982
enBlogsSubset <- sample(enBlogs, size=enBlogsLines*.01, replace=FALSE) #8992 lines
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.01, replace=FALSE) #8992 lines
trigram <- ngramTailFinder("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3)
system.time(enBlogsQuadgrams <- dfm(enBlogsSubset, ngrams = 4, verbose = TRUE))
enBlogsQuadFreq <- colSums(enBlogsQuadgrams)
enBlogsQuadFreq <- sort(enBlogsQuadFreq, decreasing=TRUE)
enBlogsQuadFreq.prune <- as.numeric()
for (i in 1:length(enBlogsQuadFreq)) {
if (enBlogsQuadFreq[i] > 2) {
enBlogsQuadFreq.prune <- c(enBlogsQuadFreq.prune, enBlogsQuadFreq[i]) }
}
enBlogsQuadFreq.prune
enBlogsQuadFreq.prune$
dimnames
str(enBlogsQuadFreq.prune)
class(enBlogsQuadFreq.prune)
length(enBlogsQuadFreq.prune)
a <- enBlogsQuadFreq.prune[1]
a
a <- enBlogsQuadFreq.prune[grepl(c"^",trigram),enBlogsQuadFreq.prune]
a <- enBlogsQuadFreq.prune[grepl(c("^",trigram),enBlogsQuadFreq.prune)]
a
trigram
aa <- c("^",trigram)
aa
aa <- paste(c("^", trigram), collapse="")
aa
a <- enBlogsQuadFreq.prune[grepl(paste(c("^", trigram), collapse=""),enBlogsQuadFreq.prune)]
a
enBlogsQuadFreq.prune
trigram <- "you may want to"
foundQuads <- enBlogsQuadFreq.prune[grepl(paste(c("^", trigram), collapse=""),enBlogsQuadFreq.prune)]
foundQuads
trigram <- "you_may_want"
foundQuads <- enBlogsQuadFreq.prune[grepl(paste(c("^", trigram), collapse=""),enBlogsQuadFreq.prune)]
foundQuads
foundQuads <- enBlogsQuadFreq.prune[grepl(trigram, collapse=""),enBlogsQuadFreq.prune)]
foundQuads <- enBlogsQuadFreq.prune[grepl(trigram, collapse=""),enBlogsQuadFreq.prune]
foundQuads <- enBlogsQuadFreq.prune[grepl(trigram,enBlogsQuadFreq.prune)]
foundQuads
trigram
a<-grepl(trigram,enBlogsQuadFreq.prune)
a
table(a)
a<-grepl("you_may_want",enBlogsQuadFreq.prune)
a
table(a)
a<-grepl("^you_may_want.",enBlogsQuadFreq.prune)
a
table(a)
a<-grepl("^you_may_want(.)",enBlogsQuadFreq.prune)
table(a)
a<-grepl("^you_may_want.*",enBlogsQuadFreq.prune)
table(a)
a<-grepl("you_may_want",enBlogsQuadFreq.prune)
a
table(a)
a<-grepl('you_may_want',enBlogsQuadFreq.prune)
table(a)
a<-grepl("you",enBlogsQuadFreq.prune)
table(a)
a<-grepl(".you.",enBlogsQuadFreq.prune)
table(a)
?grepl
enBlogsQuadFreq.prune
a<-grepl("3",enBlogsQuadFreq.prune)
table(a)
row.names(a)
row.names(enBlogsQuadFreq.prune)
dim(enBlogsQuadFreq.prune)
str(enBlogsQuadFreq.prune)
enBlogsQuadFreq.prune$names
enBlogsQuadFreq.prune[names]
enBlogsQuadFreq.prune[names,]
enBlogsQuadFreq.prune[,names]
enBlogsQuadFreq.prune$attr$names
class(enBlogsQuadFreq.prune)
names(enBlogsQuadFreq.prune)
foundQuads <- enBlogsQuadFreq.prune[grepl(paste(c("^", trigram), collapse=""),names(enBlogsQuadFreq.prune)]
foundQuads <- enBlogsQuadFreq.prune[grepl(paste(c("^", trigram), collapse=""),names(enBlogsQuadFreq.prune))]
foundQuads
trigram <- ngramTailFinder("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3)
system.time(enBlogsQuadgrams <- dfm(enBlogsSubset, ngrams = 4, verbose = TRUE))
enBlogsQuadFreq <- colSums(enBlogsQuadgrams)
enBlogsQuadFreq <- sort(enBlogsQuadFreq, decreasing=TRUE)
enBlogsQuadFreq.prune <- as.numeric()
for (i in 1:length(enBlogsQuadFreq)) {
if (enBlogsQuadFreq[i] > 2) {
enBlogsQuadFreq.prune <- c(enBlogsQuadFreq.prune, enBlogsQuadFreq[i]) }
}
foundQuads <- enBlogsQuadFreq.prune[grepl(paste(c("^", trigram), collapse=""),names(enBlogsQuadFreq.prune))]
foundQuads
trigram
library(stringi)
library(tm)
library(quanteda)
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder.R')
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt") #user 3.437, system .496, elapsed 3.982
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.25, replace=FALSE)
trigram <- ngramTailFinder("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3)
enBlogsQuadgrams <- dfm(enBlogsSubset, ngrams = 4, verbose = TRUE)
enBlogsQuadFreq <- colSums(enBlogsQuadgrams)
enBlogsQuadFreq <- sort(enBlogsQuadFreq, decreasing=TRUE)
enBlogsQuadFreq.prune <- as.numeric()
for (i in 1:length(enBlogsQuadFreq)) {
if (enBlogsQuadFreq[i] > 2) {
enBlogsQuadFreq.prune <- c(enBlogsQuadFreq.prune, enBlogsQuadFreq[i]) }
}
foundQuads <- enBlogsQuadFreq.prune[grepl(paste(c("^", trigram), collapse=""),names(enBlogsQuadFreq.prune))]
for (i in 1:length(enBlogsQuadFreq)) {
if (enBlogsQuadFreq[i] > 2) {
enBlogsQuadFreq.prune <- c(enBlogsQuadFreq.prune, enBlogsQuadFreq[i]) }
}
foundQuads <- enBlogsQuadFreq[grepl(paste(c("^", trigram), collapse=""),names(enBlogsQuadFreq))]
foundQuads
class(enBlogsQuadFreq)
names(enBlogsQuadFreq)
trigram
trigram <- ngramTailFinder("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3)
trigram
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder.R')
trigram <- ngramTailFinder("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3)
trigram
foundQuads <- enBlogsQuadFreq[grepl(paste(c("^", trigram), collapse=""),names(enBlogsQuadFreq))]
foundQuads
devtools::install_github("kbenoit/quanteda”)
devtools::install_github("kbenoit/quanteda”)
library(devtools)
devtools::install_github("kbenoit/quanteda”)
install_github("kbenoit/quanteda”)
library(Rtools)
install.packages("Rtools")
library(Rtools)
librar(XCode)
library(Xcode)
setwd("~/datasciencecoursera/Courses/Capstone/capstoneproject")
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder.R')
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor.R')
NextWordPredictor("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3)
foundGrams
names(foundGrams) <- ngramTailFinder(names(foundGrams),1)
class(enBlogsGrams)
NextWordPredictor("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3)
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor.R')
NextWordPredictor("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3)
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt") #user 3.437, system .496, elapsed 3.982
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.01, replace=FALSE)
foundTail <- ngramTailFinder(input, n)
enBlogsGrams <- dfm(enBlogsSubset, ngrams = n+1, verbose = TRUE)
enBlogsGramsFreq <- colSums(enBlogsGrams)
enBlogsGramsFreq <- sort(enBlogsGramsFreq, decreasing=TRUE)
foundGrams <- enBlogsGramsFreq[grepl(paste(c("^", foundTail), collapse=""),names(enBlogsGramsFreq))]
devtools::install_github("kbenoit/quantedaData")
setwd("~/datasciencecoursera/Courses/Capstone/capstoneproject")
path <- "~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final"
#english blogs
enBlogs <- readLines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt")
#english twitter
enTwitter <- readLines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.twitter.txt")
#english news
enNews <- readLines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.news.txt")
enBlogsLines <- length(enBlogs)
enBlogsChars <- sum(nchar(enBlogs))
enBlogsWords <- unlist(strsplit(enBlogs,split=" "))
enBlogsNumWords <- length(enBlogsWords)
enBlogsWordsUnique <- length(unique(enBlogsWords))
enTwitterLines <- length(enTwitter)
enTwitterChars <- sum(nchar(enTwitter))
enTwitterWords <- unlist(strsplit(enTwitter,split=" "))
enTwitterNumWords <- length(enTwitterWords)
enTwitterWordsUnique <- length(unique(enTwitterWords))
enNewsLines <- length(enNews)
enNewsChars <- sum(nchar(enNews))
enNewsWords <- unlist(strsplit(enNews,split=" "))
enNewsNumWords <- length(enNewsWords)
enNewsWordsUnique <- length(unique(enNewsWords))
dataSummary <- data.frame(Data = character(), Line_Count = integer(), Word_Count = integer(),
Unique_Words = integer(), Total_Characters = integer(),
stringsAsFactors=FALSE)
dataSummary[1,1] <- "Blogs"
dataSummary[1,2] <- enBlogsLines
dataSummary[1,3] <- enBlogsNumWords
dataSummary[1,4] <- enBlogsWordsUnique
dataSummary[1,5] <- enBlogsChars
dataSummary[2,1] <- c("Twitter")
dataSummary[2,2] <- enTwitterLines
dataSummary[2,3] <- enTwitterNumWords
dataSummary[2,4] <- enTwitterWordsUnique
dataSummary[2,5] <- enTwitterChars
dataSummary[3,1] <- c("News")
dataSummary[3,2] <- enNewsLines
dataSummary[3,3] <- enNewsNumWords
dataSummary[3,4] <- enNewsWordsUnique
dataSummary[3,5] <- enNewsChars
library(gridExtra)
grid.table(dataSummary)
library(quanteda)
set.seed(100)
enBlogsSubset <- sample(enBlogs, size=enBlogsLines*.01, replace=FALSE) #8992 lines
enTwitterSubset <- sample(enTwitter, size=enTwitterLines*.01, replace=FALSE) #23601 lines
enNewsSubset <- sample(enNews, size=enNewsLines*.01, replace=FALSE) #10102 lines
enSubset <- c(enBlogsSubset, enTwitterSubset, enNewsSubset) #for dfm
en.analyze.dfm.unigrams <- dfm(enSubset, ignoredFeatures = stopwords("english"), stem = TRUE, ngrams = 1, verbose = FALSE)
en.analyze.dfm.uni.freq <- colSums(en.analyze.dfm.unigrams)
uni.freq <- topfeatures(en.analyze.dfm.unigrams, n = nfeature(en.analyze.dfm.unigrams))
#uni.freq <- sort(en.analyze.dfm.uni.freq, decreasing=TRUE)
uni.freq.prune <- uni.freq[uni.freq > 10]
uni.freq.prune
en.analyze.dfm.bigrams <- dfm(enSubset, ignoredFeatures = stopwords("english"), stem = TRUE, ngrams = 2, verbose = FALSE)
en.analyze.dfm.bi.freq <- colSums(en.analyze.dfm.bigrams)
bi.freq <- topfeatures(en.analyze.dfm.bigrams, n = nfeature(en.analyze.dfm.bigrams))
#bi.freq <- sort(en.analyze.dfm.bi.freq, decreasing=TRUE)
bi.freq.prune <- bi.freq[bi.freq > 10]
bi.freq.prune
en.analyze.dfm.trigrams <- dfm(enSubset, ignoredFeatures = stopwords("english"), stem = TRUE, ngrams = 3, verbose = FALSE)
en.analyze.dfm.tri.freq <- colSums(en.analyze.dfm.trigrams)
tri.freq <- topfeatures(en.analyze.dfm.trigrams, n = nfeature(en.analyze.dfm.trigrams))
#tri.freq <- sort(en.analyze.dfm.tri.freq, decreasing=TRUE)
tri.freq.prune <- tri.freq[tri.freq > 5]
tri.freq.prune
en.analyze.dfm.quadgrams <- dfm(enSubset, ignoredFeatures = stopwords("english"), stem = TRUE, ngrams = 4, verbose = FALSE)
en.analyze.dfm.quad.freq <- colSums(en.analyze.dfm.quadgrams)
quad.freq <- topfeatures(en.analyze.dfm.quadgrams, n = nfeature(en.analyze.dfm.quadgrams))
#quad.freq <- sort(en.analyze.dfm.quad.freq, decreasing=TRUE)
quad.freq.prune <- quad.freq[quad.freq > 2]
quad.freq.prune
en.analyze.dfm.pentagrams <- dfm(enSubset, ignoredFeatures = stopwords("english"), stem = TRUE, ngrams = 5, verbose = FALSE)
en.analyze.dfm.penta.freq <- colSums(en.analyze.dfm.pentagrams)
penta.freq <- topfeatures(en.analyze.dfm.pentagrams, n = nfeature(en.analyze.dfm.pentagrams))
#penta.freq <- sort(en.analyze.dfm.penta.freq, decreasing=TRUE)
penta.freq.prune <- penta.freq[penta.freq > 2]
penta.freq.prune
---
?quanteda
library(quanteda)
info(quanteda)
installed.packages(quanteda)
installed.packages("quanteda")
str(installed.packages("quanteda"))
a <- installed.packages("quanteda")
str(a)
a[,1]
a[1,]
a[1]
a[,1:5]
plic <- installed.packages(.Library, priority = "high", fields = "Package")
table(plic[,"Package"])
vlic <- installed.packages(.Library, priority = "high", fields = "Version")
table(vlic[,"Version"])
session(Info)
sessionInfo()
library(stringi)
library(tm)
library(quanteda)
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder.R')
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt") #user 3.437, system .496, elapsed 3.982
set.seed(100)
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.25, replace=FALSE)
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder.R')
library(stringi)
library(tm)
library(quanteda)
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt") #user 3.437, system .496, elapsed 3.982
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.01, replace=FALSE)
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt") #user 3.437, system .496, elapsed 3.982
set.seed(100)
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.01, replace=FALSE)
foundTail <- ngramTailFinder("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3)
n=3
enBlogsGrams <- dfm(enBlogsSubset, ngrams = n+1, verbose = TRUE)
enBlogsGramsfreq <- topfeatures(enBlogsGrams, n = nfeature(enBlogsGrams))
enBlogsGramsFreq
enBlogsGramsFreq <- topfeatures(enBlogsGrams, n = nfeature(enBlogsGrams))
rm(enBlogsGramsfreq)
enBlogsGramsFreq
head(enBlogsGramsFreq)
length(enBlogsGramsFreq)
enBlogsGramsFreq.prune <- enBlogsGramsFreq[enBlogsGramsFreq > 1]
length(enBlogsGramsFreq.prune)
tail(enBlogsGramsFreq.prune)
paste(c("^", foundTail)
)
paste(c("^", foundTail), collapse="")
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", foundTail), collapse=""),names(enBlogsGramsFreq.prune))]
foundGrams
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", "in_the_uk"), collapse=""),names(enBlogsGramsFreq.prune))]
foundGrams
foundGrams <- enBlogsGramsFreq.prune[grepl(paste("in_the_uk", collapse=""),names(enBlogsGramsFreq.prune))]
foundGrams
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", "in_the_uk"), collapse=""),names(enBlogsGramsFreq.prune))]
foundGrams
names(foundGrams) <- ngramTailFinder(names(foundGrams),1)
foundGrams
names(foundGrams)
names(foundGrams) <- names(foundGrams[ngramTailFinder(names(foundGrams),1)])
foundGrams
foundGrams <- names(foundGrams[ngramTailFinder(names(foundGrams),1)])
foundGrams
names(foundGrams) <- names(foundGrams[ngramTailFinder(names(foundGrams),1)])
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", foundTail), collapse=""),names(enBlogsGramsFreq.prune))]
names(foundGrams) <- names(foundGrams[ngramTailFinder(names(foundGrams),1)])
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", "in_the_uk""), collapse=""),names(enBlogsGramsFreq.prune))]
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", "in_the_uk"), collapse=""),names(enBlogsGramsFreq.prune))]
foundGrams
ngramTailFinder(names(foundGrams),1)
class(names(foundGrams))
ngramTailFinder("in_the_uk_and",1)
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder.R')
library(stringi)
library(tm)
library(quanteda)
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt") #user 3.437, system .496, elapsed 3.982
set.seed(100)
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.01, replace=FALSE)
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor.R')
NextWordPredictor("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3, " ")
NextWordPredictor("in the uk", 3, " ")
enBlogsGrams <- dfm(enBlogsSubset, ngrams = n+1, verbose = TRUE)
enBlogsGramsFreq <- topfeatures(enBlogsGrams, n = nfeature(enBlogsGrams))
n=3
enBlogsGrams <- dfm(enBlogsSubset, ngrams = n+1, verbose = TRUE)
enBlogsGramsFreq <- topfeatures(enBlogsGrams, n = nfeature(enBlogsGrams))
enBlogsGramsFreq.prune <- enBlogsGramsFreq[enBlogsGramsFreq > 1]
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", "in_the_uk"), collapse=""),names(enBlogsGramsFreq.prune))]
names(foundGrams) <- names(foundGrams[ngramTailFinder(names(foundGrams),1, "_")])
foundGrams
names(foundGrams)
ngramTailFinder(names(foundGrams),1, "_")
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder1.R')
names(foundGrams) <- names(foundGrams[ngramTailFinder1(names(foundGrams), "_")])
foundGrams
ngramTailFinder1(names(foundGrams), "_")
names(FoundGrams)
names(foundGrams)
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", foundTail), collapse=""),names(enBlogsGramsFreq.prune))]
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", "in_the_uk"), collapse=""),names(enBlogsGramsFreq.prune))]
names(foundGrams) <- names(foundGrams[ngramTailFinder1(names(foundGrams), "_")])
foundGrams
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", "in_the_uk"), collapse=""),names(enBlogsGramsFreq.prune))]
foundGrams
ngramTailFinder1(names(foundGrams), "_")
names(foundGrams) <- foundGrams[names(foundGrams[ngramTailFinder1(names(foundGrams), "_")])]
FoundGrams
foundGrams
?sapply
names(foundGrams) <- names(foundGrams[sapply(names(foundGrams), ngramTailFinder1(names(foundGrams), "_")])
names(foundGrams) <- names(foundGrams[sapply(names(foundGrams), ngramTailFinder1(names(foundGrams), "_"))])
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", "in_the_uk"), collapse=""),names(enBlogsGramsFreq.prune))]
names(foundGrams) <- names(foundGrams[sapply(names(foundGrams), ngramTailFinder1(names(foundGrams), "_"))])
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("^", "in_the_uk"), collapse=""),names(enBlogsGramsFreq.prune))]
foundGrams
names <- names(foundGrams)
names
names[1]
ngramTailFinder1(names[1], "_")
ngramTailFinder1(names, "_")
names(foundGrams) <- ngramTailFinder1(names, "_")
foundGrams
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("in_the_uk"), collapse=""),names(enBlogsGramsFreq.prune))]
foundGrams
names(foundGrams) <- ngramTailFinder1(names(foundGrams), "_")
foundGrams
enBlogsGramsFreq.prune
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("you_have_to"), collapse=""),names(enBlogsGramsFreq.prune))]
names(foundGrams) <- ngramTailFinder1(names(foundGrams), "_")
return(foundGrams)
foundGrams
ngramTailFinder1(names(foundGrams), "_")
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("you_have_to"), collapse=""),names(enBlogsGramsFreq.prune))]
ngramTailFinder1(names(foundGrams), "_")
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("you_have_to"), collapse=""),names(enBlogsGramsFreq.prune))]
names(foundGrams)
names(foundGrams)[1]
foundGrams <- enBlogsGramsFreq.prune[grepl(paste(c("you_have_to"), collapse=""),names(enBlogsGramsFreq.prune))]
for (i in 1:length(foundGrams)){
names(foundGrams)[i] <- ngramTailFinder1(names(foundGrams)[i], "_")
}
foundGrams
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor.R')
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder.R')
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder1.R')
NextWordPredictor("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3, " ")
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/NextWordPredictor.R')
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder1.R')
NextWordPredictor("The guy in front of me just bought a pound of bacon, a bouquet, and a case of", 3, " ")
?dfm
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt") #user 3.437, system .496, elapsed 3.982
set.seed(100)
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.25, replace=FALSE)
enBlogsGrams <- dfm(enBlogsSubset, ngrams = n+1, verbose = TRUE)
save(enBlogsGrams, file="~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsGrams.RData")
save(enBlogsGrams, file="~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsGrams.RData")
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder.R')
source('~/datasciencecoursera/Courses/Capstone/capstoneproject/ngramTailFinder1.R')
library(stringi)
library(tm)
library(quanteda)
?ls
system.time(enBlogsGrams <- load("~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsGrams.RData"))
enBlogsGrams
class(enBlogsGrams)
enBlogs <- stri_read_lines("~/datasciencecoursera/Courses/Capstone/Coursera-SwiftKey/final/en_US/en_US.blogs.txt") #user 3.437, system .496, elapsed 3.982
set.seed(100)
enBlogsSubset <- sample(enBlogs, size=length(enBlogs)*.01, replace=FALSE)
enBlogsUnigrams <- dfm(enBlogsSubset, ngrams = 1)
save(enBlogsUnigrams, file="~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsUnigrams.RData")
unlink("enBlogsUnigrams.RData")
unlink(".RData")
enBlogsGrams <- load("~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsUnigrams.RData")
enBlogsUnigrams
unlink("~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsUnigrams.RData")
unlink("~/datasciencecoursera/Courses/Capstone/capstoneproject/.RData")
save(enBlogsUnigrams, file="~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsUnigrams.RData")
unlink("~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsUnigrams.RData")
unlink("~/datasciencecoursera/Courses/Capstone/capstoneproject/.RData")
unlink("~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsGrams.RData")
unlink("~/datasciencecoursera/Courses/Capstone/capstoneproject/.RData")
save(enBlogsUnigrams, file="~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsUnigrams.RData")
unlink("~/datasciencecoursera/Courses/Capstone/capstoneproject/enBlogsUnigrams.RData")
unlink("~/datasciencecoursera/Courses/Capstone/capstoneproject/.RData")
enBlogsUnigrams
